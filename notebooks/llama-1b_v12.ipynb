{"cells":[{"cell_type":"code","source":["# ============================================================================\n","# ABSTRA Framework: Automated Scientific Discovery Pipeline\n","# Phase 1-4 Implementation (Literature Processing â†’ Hypothesis Refinement)\n","# ============================================================================"],"metadata":{"id":"yGSsZ8zd7jXQ","executionInfo":{"status":"ok","timestamp":1758506004577,"user_tz":-60,"elapsed":4,"user":{"displayName":"Adnan Mahmud","userId":"07888148650890682117"}}},"execution_count":23,"outputs":[]},{"cell_type":"code","source":["!pip install captum==0.7.0 transformers accelerate -q"],"metadata":{"id":"FYoiE1DG7qTO","executionInfo":{"status":"ok","timestamp":1758506014672,"user_tz":-60,"elapsed":10082,"user":{"displayName":"Adnan Mahmud","userId":"07888148650890682117"}}},"execution_count":24,"outputs":[]},{"cell_type":"code","source":["import torch\n","from transformers import AutoTokenizer, AutoModelForCausalLM\n","import numpy as np\n","import pandas as pd\n","from captum.attr import FeatureAblation, ShapleyValueSampling, LLMAttribution, TextTemplateInput\n","import nltk\n","import json\n","import gc\n","import os\n","import time\n","import re\n","from tqdm import tqdm\n","import logging\n","from google.colab import drive"],"metadata":{"id":"YfIjEJq98LCw","executionInfo":{"status":"ok","timestamp":1758506014697,"user_tz":-60,"elapsed":26,"user":{"displayName":"Adnan Mahmud","userId":"07888148650890682117"}}},"execution_count":25,"outputs":[]},{"cell_type":"code","source":["# Cell 3: Mount Drive and Setup\n","drive.mount('/content/drive')\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","nltk.download('punkt', quiet=True)\n","print(f\"Using device: {device}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Zxsby70o8SVh","executionInfo":{"status":"ok","timestamp":1758506016905,"user_tz":-60,"elapsed":2205,"user":{"displayName":"Adnan Mahmud","userId":"07888148650890682117"}},"outputId":"cee80597-0317-4ef5-b551-1f46c3ee7b49"},"execution_count":26,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","Using device: cuda\n"]}]},{"cell_type":"code","source":["# Cell 4: Configuration\n","class Config:\n","    \"\"\"Centralized configuration for the ABSTRA pipeline\"\"\"\n","    MODEL_NAME = \"TinyLlama/TinyLlama-1.1B-Chat-v1.0\"\n","    CSV_PATH = '/content/drive/My Drive/llm_hyp/Data/raw_data_2.csv'\n","    OUTPUT_DIR = '/content/drive/My Drive/llm_hyp/results/pre_final'\n","    BATCH_SIZE = 16\n","    NUM_HYPOTHESES = 3"],"metadata":{"id":"c09wmN1z8UU3","executionInfo":{"status":"ok","timestamp":1758506016926,"user_tz":-60,"elapsed":16,"user":{"displayName":"Adnan Mahmud","userId":"07888148650890682117"}}},"execution_count":27,"outputs":[]},{"cell_type":"code","source":["# Cell 5: Utility Functions\n","def setup_logging(output_dir):\n","    \"\"\"Setup logging\"\"\"\n","    os.makedirs(output_dir, exist_ok=True)\n","    log_path = os.path.join(output_dir, 'abstra_log.txt')\n","\n","    # Clear existing handlers\n","    for handler in logging.root.handlers[:]:\n","        logging.root.removeHandler(handler)\n","\n","    logging.basicConfig(\n","        level=logging.INFO,\n","        format='%(asctime)s - %(levelname)s - %(message)s',\n","        handlers=[\n","            logging.FileHandler(log_path, mode='w'),\n","            logging.StreamHandler()\n","        ]\n","    )\n","    logger = logging.getLogger(__name__)\n","    logger.info(f\"Logging to {log_path}\")\n","    return logger\n","\n","def clear_memory():\n","    \"\"\"Clear GPU memory\"\"\"\n","    if torch.cuda.is_available():\n","        torch.cuda.empty_cache()\n","    gc.collect()\n"],"metadata":{"id":"rEAT8UhB9h_L","executionInfo":{"status":"ok","timestamp":1758506016939,"user_tz":-60,"elapsed":10,"user":{"displayName":"Adnan Mahmud","userId":"07888148650890682117"}}},"execution_count":28,"outputs":[]},{"cell_type":"code","source":["# Cell 6: Model Management\n","def load_model_and_tokenizer(model_name=Config.MODEL_NAME):\n","    \"\"\"Load model and tokenizer\"\"\"\n","    print(f\"Loading model: {model_name}\")\n","    tokenizer = AutoTokenizer.from_pretrained(model_name)\n","    tokenizer.pad_token = tokenizer.eos_token\n","    tokenizer.padding_side = 'left'\n","\n","    model = AutoModelForCausalLM.from_pretrained(\n","        model_name,\n","        torch_dtype=torch.float16,\n","        low_cpu_mem_usage=True\n","    ).to(device)\n","    model.eval()\n","    print(\"Model loaded successfully\")\n","    return model, tokenizer\n","\n","def generate_response(prompt, model, tokenizer, max_length=3000):\n","    \"\"\"Generate LLM response\"\"\"\n","    try:\n","        messages = [{\"role\": \"user\", \"content\": prompt}]\n","        chat = tokenizer.apply_chat_template(messages, tokenize=False)\n","        inputs = tokenizer(chat, return_tensors=\"pt\").to(device)\n","\n","        with torch.no_grad():\n","            outputs = model.generate(\n","                **inputs,\n","                max_length=max_length,\n","                temperature=0.7,\n","                do_sample=True,\n","                repetition_penalty=1.2,\n","                pad_token_id=tokenizer.eos_token_id,\n","                use_cache=True\n","            )\n","\n","        response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n","        clear_memory()\n","        return response\n","    except Exception as e:\n","        logging.error(f\"Error generating response: {str(e)}\")\n","        return \"\"\n"],"metadata":{"id":"f02_FdPD9w8T","executionInfo":{"status":"ok","timestamp":1758506016956,"user_tz":-60,"elapsed":11,"user":{"displayName":"Adnan Mahmud","userId":"07888148650890682117"}}},"execution_count":29,"outputs":[]},{"cell_type":"code","source":["# Cell 7: Phase 1 - Segmentation\n","def segment_abstract(abstract):\n","    \"\"\"Segment abstract into 5 sections\"\"\"\n","    try:\n","        sentences = nltk.sent_tokenize(abstract)\n","    except:\n","        sentences = [s.strip() for s in abstract.split('.') if s.strip()]\n","\n","    features = {\n","        'background': [],\n","        'objective': [],\n","        'methods': [],\n","        'results': [],\n","        'conclusion': []\n","    }\n","\n","    if len(sentences) <= 3:\n","        features['methods'] = sentences\n","    else:\n","        for i, sentence in enumerate(sentences):\n","            position = i / len(sentences)\n","            if position < 0.2:\n","                features['background'].append(sentence)\n","            elif position < 0.4:\n","                features['objective'].append(sentence)\n","            elif position < 0.6:\n","                features['methods'].append(sentence)\n","            elif position < 0.8:\n","                features['results'].append(sentence)\n","            else:\n","                features['conclusion'].append(sentence)\n","\n","    return features"],"metadata":{"id":"TZRfd6ym9zmK","executionInfo":{"status":"ok","timestamp":1758506016974,"user_tz":-60,"elapsed":13,"user":{"displayName":"Adnan Mahmud","userId":"07888148650890682117"}}},"execution_count":30,"outputs":[]},{"cell_type":"code","source":["# Cell 8: Phase 2 - Hypothesis Generation\n","def generate_hypotheses(abstract, title, model, tokenizer):\n","    \"\"\"Generate 3 hypotheses\"\"\"\n","    prompts = [\n","        f\"Read this scientific paper abstract and identify its main hypothesis.\\n\\nTitle: {title}\\nAbstract: {abstract}\\n\\nWhat is the main hypothesis?\",\n","        f\"Based on this abstract titled '{title}', what is the central hypothesis being tested?\\n\\nAbstract: {abstract}\",\n","        f\"Scientific Abstract: {abstract}\\nTitle: {title}\\n\\nExtract the primary research hypothesis. Be specific.\"\n","    ]\n","\n","    hypotheses = []\n","    for i, prompt in enumerate(prompts):\n","        hyp_text = generate_response(prompt, model, tokenizer)\n","        # Clean response\n","        if \"<|assistant|>\" in hyp_text:\n","            hyp_text = hyp_text.split(\"<|assistant|>\")[1].strip()\n","\n","        hypotheses.append({\n","            'hypothesis_id': i + 1,\n","            'hypothesis_text': hyp_text\n","        })\n","\n","    return hypotheses\n"],"metadata":{"id":"FEO1QV2y917A","executionInfo":{"status":"ok","timestamp":1758506017186,"user_tz":-60,"elapsed":201,"user":{"displayName":"Adnan Mahmud","userId":"07888148650890682117"}}},"execution_count":31,"outputs":[]},{"cell_type":"code","source":["# Cell 9: Phase 3 - Feature Ablation\n","def compute_feature_ablation(features, hypothesis, model, tokenizer):\n","    \"\"\"Compute FA scores\"\"\"\n","    all_sentences = []\n","    feature_indices = {}\n","    current_idx = 0\n","\n","    for section in ['background', 'objective', 'methods', 'results', 'conclusion']:\n","        feature_indices[section] = (current_idx, current_idx + len(features[section]))\n","        all_sentences.extend(features[section])\n","        current_idx += len(features[section])\n","\n","    if not all_sentences:\n","        return {s: 0.0 for s in ['background', 'objective', 'methods', 'results', 'conclusion']}\n","\n","    try:\n","        template = \" \".join([\"{}\"]*len(all_sentences))\n","        inp = TextTemplateInput(template, values=all_sentences)\n","\n","        fa = FeatureAblation(model)\n","        llm_attr = LLMAttribution(fa, tokenizer)\n","\n","        with torch.amp.autocast('cuda'):\n","            attr_res = llm_attr.attribute(inp, target=hypothesis, skip_tokens=torch.tensor([1]))\n","\n","        section_scores = {}\n","        for section, (start, end) in feature_indices.items():\n","            section_scores[section] = attr_res.seq_attr[start:end].mean().item() if end > start else 0.0\n","\n","        clear_memory()\n","        return section_scores\n","    except Exception as e:\n","        logging.error(f\"FA error: {str(e)}\")\n","        return {s: 0.0 for s in ['background', 'objective', 'methods', 'results', 'conclusion']}\n"],"metadata":{"id":"1r_YTu2194zH","executionInfo":{"status":"ok","timestamp":1758506017214,"user_tz":-60,"elapsed":39,"user":{"displayName":"Adnan Mahmud","userId":"07888148650890682117"}}},"execution_count":32,"outputs":[]},{"cell_type":"code","source":["# Cell 10: Phase 3 - Shapley Values\n","def compute_shapley_values(features, hypothesis, model, tokenizer):\n","    \"\"\"Compute Shapley scores\"\"\"\n","    all_sentences = []\n","    feature_indices = {}\n","    current_idx = 0\n","\n","    for section in ['background', 'objective', 'methods', 'results', 'conclusion']:\n","        feature_indices[section] = (current_idx, current_idx + len(features[section]))\n","        all_sentences.extend(features[section])\n","        current_idx += len(features[section])\n","\n","    if not all_sentences:\n","        return {s: 0.0 for s in ['background', 'objective', 'methods', 'results', 'conclusion']}\n","\n","    try:\n","        template = \" \".join([\"{}\"]*len(all_sentences))\n","        inp = TextTemplateInput(template, values=all_sentences)\n","\n","        shapley = ShapleyValueSampling(model)\n","        llm_attr = LLMAttribution(shapley, tokenizer)\n","\n","        with torch.amp.autocast('cuda'):\n","            attr_res = llm_attr.attribute(inp, target=hypothesis, n_samples=10)\n","\n","        section_scores = {}\n","        for section, (start, end) in feature_indices.items():\n","            section_scores[section] = attr_res.seq_attr[start:end].mean().item() if end > start else 0.0\n","\n","        clear_memory()\n","        return section_scores\n","    except Exception as e:\n","        logging.error(f\"Shapley error: {str(e)}\")\n","        return {s: 0.0 for s in ['background', 'objective', 'methods', 'results', 'conclusion']}"],"metadata":{"id":"SzqwyOg297un","executionInfo":{"status":"ok","timestamp":1758506017217,"user_tz":-60,"elapsed":28,"user":{"displayName":"Adnan Mahmud","userId":"07888148650890682117"}}},"execution_count":33,"outputs":[]},{"cell_type":"code","source":["# Cell 11: Phase 3 - Self-Evaluation\n","def self_evaluate_hypothesis(title, abstract, hypothesis, model, tokenizer):\n","    \"\"\"Self-evaluate hypothesis quality\"\"\"\n","    prompt = f\"\"\"<|system|>\n","You are an expert scientific evaluator. Assess how well this hypothesis represents the paper abstract.\n","\n","<|user|>\n","PAPER TITLE: {title}\n","\n","ABSTRACT:\n","{abstract}\n","\n","HYPOTHESIS:\n","{hypothesis}\n","\n","Evaluate this hypothesis on a scale of 0.0 to 1.0 based on:\n","1. Clarity and specificity\n","2. Alignment with abstract content\n","3. Scientific validity\n","4. Testability\n","\n","Provide your score as \"FINAL SCORE: X.X\" (one decimal place).\n","\n","<|assistant|>\n","\"\"\"\n","\n","    response = generate_response(prompt, model, tokenizer, max_length=1024)\n","\n","    # Extract score\n","    match = re.search(r\"FINAL SCORE:\\s*(\\d+\\.?\\d*)\", response, re.IGNORECASE)\n","    if match:\n","        score = float(match.group(1))\n","        return round(min(max(score, 0), 1), 1), response\n","\n","    # Fallback\n","    matches = re.findall(r\"(\\d+\\.\\d+)\", response)\n","    for m in matches:\n","        num = float(m)\n","        if 0 <= num <= 1:\n","            return round(num, 1), response\n","\n","    return 0.5, response\n"],"metadata":{"id":"POM2zydRHKN6","executionInfo":{"status":"ok","timestamp":1758506017219,"user_tz":-60,"elapsed":27,"user":{"displayName":"Adnan Mahmud","userId":"07888148650890682117"}}},"execution_count":34,"outputs":[]},{"cell_type":"code","source":["# Cell 12: Main Processing\n","def process_single_abstract(row, model, tokenizer, logger):\n","    \"\"\"Process one abstract\"\"\"\n","    title = row['Title']  # Capitalized column name\n","    abstract = row['Abstract']  # Capitalized column name\n","\n","    logger.info(f\"Processing: {title}\")\n","\n","    result = {\n","        'title': title,\n","        'abstract': abstract,\n","        'hypotheses': [],\n","        'attribution_results': []\n","    }\n","\n","    # Phase 1: Segment\n","    features = segment_abstract(abstract)\n","    result['features'] = features\n","    logger.info(f\"  Segmented into {sum(len(v) for v in features.values())} sentences\")\n","\n","    # Phase 2: Generate hypotheses\n","    hypotheses = generate_hypotheses(abstract, title, model, tokenizer)\n","    result['hypotheses'] = hypotheses\n","    logger.info(f\"  Generated {len(hypotheses)} hypotheses\")\n","\n","    # Phase 3: Attribution & Evaluation\n","    for hyp_data in hypotheses:\n","        hyp_id = hyp_data['hypothesis_id']\n","        hyp_text = hyp_data['hypothesis_text']\n","        logger.info(f\"  Processing hypothesis {hyp_id}\")\n","\n","        # FA\n","        fa_scores = compute_feature_ablation(features, hyp_text, model, tokenizer)\n","\n","        # Shapley\n","        shapley_scores = compute_shapley_values(features, hyp_text, model, tokenizer)\n","\n","        # Self-eval\n","        eval_score, eval_text = self_evaluate_hypothesis(title, abstract, hyp_text, model, tokenizer)\n","\n","        result['attribution_results'].append({\n","            'hypothesis_id': hyp_id,\n","            'fa_scores': fa_scores,\n","            'shapley_scores': shapley_scores,\n","            'self_eval_score': eval_score,\n","            'self_eval_text': eval_text\n","        })\n","\n","        clear_memory()\n","\n","    return result"],"metadata":{"id":"wui4zfXi-BKo","executionInfo":{"status":"ok","timestamp":1758506017223,"user_tz":-60,"elapsed":20,"user":{"displayName":"Adnan Mahmud","userId":"07888148650890682117"}}},"execution_count":35,"outputs":[]},{"cell_type":"code","source":["# Cell 13: Create Output CSV\n","def create_output_csv(results, output_path):\n","    \"\"\"Create final CSV matching expected format\"\"\"\n","    rows = []\n","\n","    for result in results:\n","        title = result['title']\n","        abstract = result['abstract']\n","        features = result['features']\n","\n","        for hyp_data in result['hypotheses']:\n","            hyp_id = hyp_data['hypothesis_id']\n","            hyp_text = hyp_data['hypothesis_text']\n","\n","            # Find attribution\n","            attr = next(a for a in result['attribution_results'] if a['hypothesis_id'] == hyp_id)\n","\n","            row = {\n","                'title': title,\n","                'abstract': abstract,\n","                'hypothesis_id': hyp_id,\n","                'hypothesis': hyp_text,\n","                'model_self_evaluated_score': attr['self_eval_score'],  # Match expected column name\n","                'model_response': attr['self_eval_text'],\n","                # Add segmented sections\n","                'abstract_background': ' '.join(features['background']),\n","                'abstract_objective': ' '.join(features['objective']),\n","                'abstract_methods': ' '.join(features['methods']),\n","                'abstract_results': ' '.join(features['results']),\n","                'abstract_conclusion': ' '.join(features['conclusion']),\n","            }\n","\n","            # FA scores\n","            for section, score in attr['fa_scores'].items():\n","                row[f'fa_{section}'] = score\n","\n","            # Shapley scores\n","            for section, score in attr['shapley_scores'].items():\n","                row[f'shapley_{section}'] = score\n","\n","            rows.append(row)\n","\n","    df = pd.DataFrame(rows)\n","    df.to_csv(output_path, index=False)\n","    return df\n"],"metadata":{"id":"7RUVj0Bi-DeR","executionInfo":{"status":"ok","timestamp":1758506017241,"user_tz":-60,"elapsed":15,"user":{"displayName":"Adnan Mahmud","userId":"07888148650890682117"}}},"execution_count":36,"outputs":[]},{"cell_type":"code","source":["# Cell 14: Main Pipeline\n","def main():\n","    \"\"\"Execute ABSTRA pipeline\"\"\"\n","    logger = setup_logging(Config.OUTPUT_DIR)\n","    logger.info(\"=\"*50)\n","    logger.info(\"Starting ABSTRA Pipeline\")\n","    logger.info(\"=\"*50)\n","\n","    # Load CSV\n","    logger.info(f\"Loading CSV from: {Config.CSV_PATH}\")\n","    try:\n","        df = pd.read_csv(Config.CSV_PATH)\n","        logger.info(f\"Loaded {len(df)} abstracts\")\n","        logger.info(f\"Columns: {list(df.columns)}\")\n","    except Exception as e:\n","        logger.error(f\"Failed to load CSV: {str(e)}\")\n","        return None\n","\n","    # Load model\n","    model, tokenizer = load_model_and_tokenizer()\n","\n","    # Process abstracts\n","    results = []\n","    for idx, row in df.iterrows():\n","        try:\n","            logger.info(f\"\\n--- Processing abstract {idx+1}/{len(df)} ---\")\n","            result = process_single_abstract(row, model, tokenizer, logger)\n","            results.append(result)\n","        except Exception as e:\n","            logger.error(f\"Error processing row {idx}: {str(e)}\")\n","            import traceback\n","            logger.error(traceback.format_exc())\n","            continue\n","\n","    if not results:\n","        logger.error(\"No results generated!\")\n","        return None\n","\n","    # Save JSON\n","    json_path = os.path.join(Config.OUTPUT_DIR, 'complete_results.json')\n","    with open(json_path, 'w') as f:\n","        json.dump(results, f, indent=2)\n","    logger.info(f\"Saved JSON to {json_path}\")\n","\n","    # Create CSV\n","    csv_path = os.path.join(Config.OUTPUT_DIR, 'abstra_results.csv')\n","    output_df = create_output_csv(results, csv_path)\n","    logger.info(f\"Saved CSV to {csv_path}\")\n","    logger.info(f\"CSV shape: {output_df.shape}\")\n","\n","    logger.info(\"=\"*50)\n","    logger.info(\"Pipeline Complete!\")\n","    logger.info(\"=\"*50)\n","\n","    return output_df\n"],"metadata":{"id":"cOBpkIvi-Fy1","executionInfo":{"status":"ok","timestamp":1758506017243,"user_tz":-60,"elapsed":7,"user":{"displayName":"Adnan Mahmud","userId":"07888148650890682117"}}},"execution_count":37,"outputs":[]},{"cell_type":"code","source":["# Cell 15: Execute\n","if __name__ == \"__main__\":\n","    results_df = main()\n","    if results_df is not None:\n","        print(\"\\n\" + \"=\"*50)\n","        print(\"SUCCESS! Sample output:\")\n","        print(\"=\"*50)\n","        print(results_df.head())\n","        print(f\"\\nTotal rows: {len(results_df)}\")\n","        print(f\"Columns: {list(results_df.columns)}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7IZl5kLY-H4u","executionInfo":{"status":"ok","timestamp":1758509737874,"user_tz":-60,"elapsed":3720636,"user":{"displayName":"Adnan Mahmud","userId":"07888148650890682117"}},"outputId":"9826e66b-6a49-42a0-f604-bd1335bc2836"},"execution_count":38,"outputs":[{"output_type":"stream","name":"stderr","text":["2025-09-22 01:53:37,402 - INFO - Logging to /content/drive/My Drive/llm_hyp/results/pre_final/abstra_log.txt\n","2025-09-22 01:53:37,410 - INFO - ==================================================\n","2025-09-22 01:53:37,411 - INFO - Starting ABSTRA Pipeline\n","2025-09-22 01:53:37,412 - INFO - ==================================================\n","2025-09-22 01:53:37,413 - INFO - Loading CSV from: /content/drive/My Drive/llm_hyp/Data/raw_data_2.csv\n","2025-09-22 01:53:37,419 - INFO - Loaded 2 abstracts\n","2025-09-22 01:53:37,420 - INFO - Columns: ['Title', 'Abstract']\n"]},{"output_type":"stream","name":"stdout","text":["Loading model: TinyLlama/TinyLlama-1.1B-Chat-v1.0\n"]},{"output_type":"stream","name":"stderr","text":["2025-09-22 01:53:45,502 - INFO - \n","--- Processing abstract 1/2 ---\n","2025-09-22 01:53:45,503 - INFO - Processing: Automating the practice of science: Opportunities, challenges, and implications\n","2025-09-22 01:53:45,507 - INFO -   Segmented into 4 sentences\n"]},{"output_type":"stream","name":"stdout","text":["Model loaded successfully\n"]},{"output_type":"stream","name":"stderr","text":["2025-09-22 01:54:28,644 - INFO -   Generated 3 hypotheses\n","2025-09-22 01:54:28,646 - INFO -   Processing hypothesis 1\n","2025-09-22 01:59:14,509 - INFO -   Processing hypothesis 2\n","2025-09-22 02:08:57,745 - INFO -   Processing hypothesis 3\n","2025-09-22 02:16:58,682 - INFO - \n","--- Processing abstract 2/2 ---\n","2025-09-22 02:16:58,683 - INFO - Processing: Random Forests for Heteroscedastic Data\n","2025-09-22 02:16:58,686 - INFO -   Segmented into 8 sentences\n","2025-09-22 02:17:17,221 - INFO -   Generated 3 hypotheses\n","2025-09-22 02:17:17,222 - INFO -   Processing hypothesis 1\n","2025-09-22 02:30:01,847 - INFO -   Processing hypothesis 2\n","2025-09-22 02:41:02,724 - INFO -   Processing hypothesis 3\n","2025-09-22 02:55:37,991 - INFO - Saved JSON to /content/drive/My Drive/llm_hyp/results/pre_final/complete_results.json\n","2025-09-22 02:55:38,019 - INFO - Saved CSV to /content/drive/My Drive/llm_hyp/results/pre_final/abstra_results.csv\n","2025-09-22 02:55:38,021 - INFO - CSV shape: (6, 21)\n","2025-09-22 02:55:38,021 - INFO - ==================================================\n","2025-09-22 02:55:38,022 - INFO - Pipeline Complete!\n","2025-09-22 02:55:38,023 - INFO - ==================================================\n"]},{"output_type":"stream","name":"stdout","text":["\n","==================================================\n","SUCCESS! Sample output:\n","==================================================\n","                                               title  \\\n","0  Automating the practice of science: Opportunit...   \n","1  Automating the practice of science: Opportunit...   \n","2  Automating the practice of science: Opportunit...   \n","3            Random Forests for Heteroscedastic Data   \n","4            Random Forests for Heteroscedastic Data   \n","\n","                                            abstract  hypothesis_id  \\\n","0  Automation transformed various aspects of our ...              1   \n","1  Automation transformed various aspects of our ...              2   \n","2  Automation transformed various aspects of our ...              3   \n","3  Random forests are a popular machine learning ...              1   \n","4  Random forests are a popular machine learning ...              2   \n","\n","                                          hypothesis  \\\n","0  The main hypothesis of the scientific paper is...   \n","1  The central hypothesis of this abstract is tha...   \n","2  The potential impact of automation on scientif...   \n","3  The main hypothesis of this study is that by i...   \n","4  The central hypothesis being tested in this re...   \n","\n","   model_self_evaluated_score  \\\n","0                         0.0   \n","1                         0.0   \n","2                         0.0   \n","3                         0.0   \n","4                         0.0   \n","\n","                                      model_response  \\\n","0  <|user|>\\n<|system|>\\nYou are an expert scient...   \n","1  <|user|>\\n<|system|>\\nYou are an expert scient...   \n","2  <|user|>\\n<|system|>\\nYou are an expert scient...   \n","3  <|user|>\\n<|system|>\\nYou are an expert scient...   \n","4  <|user|>\\n<|system|>\\nYou are an expert scient...   \n","\n","                                 abstract_background  \\\n","0  Automation transformed various aspects of our ...   \n","1  Automation transformed various aspects of our ...   \n","2  Automation transformed various aspects of our ...   \n","3  Random forests are a popular machine learning ...   \n","4  Random forests are a popular machine learning ...   \n","\n","                                  abstract_objective  \\\n","0  In the domain of scientific inquiry, automated...   \n","1  In the domain of scientific inquiry, automated...   \n","2  In the domain of scientific inquiry, automated...   \n","3  We consider datasets where the relative amount...   \n","4  We consider datasets where the relative amount...   \n","\n","                                    abstract_methods  \\\n","0  This article evaluates the scope of automation...   \n","1  This article evaluates the scope of automation...   \n","2  This article evaluates the scope of automation...   \n","3  Utilising this uncertainty information can lea...   \n","4  Utilising this uncertainty information can lea...   \n","\n","                                    abstract_results  ... fa_background  \\\n","0  Furthermore, it discusses different perspectiv...  ...      4.576874   \n","1  Furthermore, it discusses different perspectiv...  ...      4.070129   \n","2  Furthermore, it discusses different perspectiv...  ...      4.509003   \n","3  We introduce three random forest variations to...  ...      7.468109   \n","4  We introduce three random forest variations to...  ...      7.676361   \n","\n","   fa_objective  fa_methods  fa_results  fa_conclusion  shapley_background  \\\n","0     -2.508499    1.930603   13.947113       0.000000            6.685738   \n","1      2.227325    6.284576    8.094238       0.000000            5.040131   \n","2     -3.922852   -1.555634   -2.836121       0.000000            3.146115   \n","3     20.415756   12.112183   37.223694      36.441650           14.788363   \n","4      1.638824    9.224701   36.010239       4.525696            9.255544   \n","\n","   shapley_objective  shapley_methods  shapley_results  shapley_conclusion  \n","0           0.520131        16.989183        11.383852            0.000000  \n","1           4.008405        17.566168        11.781354            0.000000  \n","2          14.008014        12.684241        -3.471884            0.000000  \n","3          17.228544        13.283930        37.260563           36.382568  \n","4           0.766054        14.414416        45.486565            1.735211  \n","\n","[5 rows x 21 columns]\n","\n","Total rows: 6\n","Columns: ['title', 'abstract', 'hypothesis_id', 'hypothesis', 'model_self_evaluated_score', 'model_response', 'abstract_background', 'abstract_objective', 'abstract_methods', 'abstract_results', 'abstract_conclusion', 'fa_background', 'fa_objective', 'fa_methods', 'fa_results', 'fa_conclusion', 'shapley_background', 'shapley_objective', 'shapley_methods', 'shapley_results', 'shapley_conclusion']\n"]}]}],"metadata":{"kernelspec":{"display_name":"llm_env","language":"python","name":"llm_env"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.11"},"colab":{"provenance":[],"gpuType":"T4"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}